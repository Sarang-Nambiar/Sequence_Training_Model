{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "with open(\"Data/ES/train\") as f:\n",
    "    es = f.read().splitlines()\n",
    "\n",
    "with open(\"Data/RU/train\") as f:\n",
    "    ru = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Data/ES/dev.in\") as f:\n",
    "    dev_in_es = f.read().splitlines()\n",
    "with open(\"Data/ES/dev.out\") as f:\n",
    "    dev_out_es = f.read().splitlines()\n",
    "with open(\"Data/RU/dev.in\") as f:\n",
    "    dev_in_ru = f.read().splitlines()\n",
    "with open(\"Data/RU/dev.out\") as f:\n",
    "    test_out_ru = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_sentences(data):\n",
    "    formatted =[]\n",
    "    innerlist = []\n",
    "    for sentence in data:\n",
    "        try:\n",
    "            if(sentence!=\"\"):\n",
    "                x, label = sentence.split(\" \")\n",
    "                innerlist.append(label)\n",
    "            if(sentence==\"\"):\n",
    "                formatted.append(innerlist.copy())\n",
    "                innerlist.clear()\n",
    "                \n",
    "        except:\n",
    "            continue\n",
    "    # print(formatted)\n",
    "    return formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "def estimate_transition_parameters_test(sentences):\n",
    "    transition_counts = {}\n",
    "    state_counts = {}\n",
    "    list_of_sentences = format_sentences(sentences)\n",
    "    for one_sentence in list_of_sentences:\n",
    "        # print(one_sentence)\n",
    "        prev_state = 'START'\n",
    "        for state in one_sentence:\n",
    "            if state_counts.get(prev_state):\n",
    "                state_counts[prev_state] +=1\n",
    "            else:\n",
    "                state_counts[prev_state] = 1\n",
    "\n",
    "            if prev_state not in transition_counts:\n",
    "                transition_counts[prev_state] = {}\n",
    "            if state not in transition_counts[prev_state]:\n",
    "                transition_counts[prev_state][state] = 1\n",
    "            else:\n",
    "                transition_counts[prev_state][state] += 1\n",
    "            prev_state = state\n",
    "        if \"END\" not in transition_counts[prev_state]:\n",
    "            transition_counts[prev_state][\"END\"] = 1\n",
    "            state_counts[prev_state] +=1\n",
    "        else: \n",
    "            transition_counts[prev_state][\"END\"] +=1\n",
    "            state_counts[prev_state] +=1\n",
    "    # print(state_counts) \n",
    "\n",
    "\n",
    "    # Calculate transition probabilities and assign a default value of 0 if the entry doesn't exist\n",
    "    for from_state, to_states in transition_counts.items():\n",
    "        for state, x in to_states.items():\n",
    "            # print(from_state,state)\n",
    "            if state not in transition_counts[from_state]:\n",
    "                transition_counts[from_state][state] = 0\n",
    "            else:\n",
    "                transition_counts[from_state][state] = transition_counts[from_state][state] / state_counts[from_state]\n",
    "\n",
    "            \n",
    "\n",
    "    # print(\"transition\", transition_counts, \"state\", state_counts)       \n",
    "    return transition_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'START': {'O': 0.9289176090468497,\n",
       "  'B-positive': 0.052234787291330104,\n",
       "  'B-negative': 0.014001077005923533,\n",
       "  'B-neutral': 0.004846526655896607},\n",
       " 'O': {'O': 0.8856896848630963,\n",
       "  'B-positive': 0.03650766316514551,\n",
       "  'END': 0.06344067504735663,\n",
       "  'B-negative': 0.012226623041157224,\n",
       "  'B-neutral': 0.0021353538832443605},\n",
       " 'B-positive': {'O': 0.871551724137931,\n",
       "  'I-positive': 0.11637931034482758,\n",
       "  'END': 0.008620689655172414,\n",
       "  'B-neutral': 0.0008620689655172414,\n",
       "  'B-positive': 0.002586206896551724},\n",
       " 'B-negative': {'O': 0.8110236220472441,\n",
       "  'I-negative': 0.1784776902887139,\n",
       "  'END': 0.010498687664041995},\n",
       " 'B-neutral': {'I-neutral': 0.20833333333333334, 'O': 0.7916666666666666},\n",
       " 'I-neutral': {'I-neutral': 0.6511627906976745, 'O': 0.3488372093023256},\n",
       " 'I-positive': {'I-positive': 0.5700636942675159,\n",
       "  'O': 0.4267515923566879,\n",
       "  'END': 0.0031847133757961785},\n",
       " 'I-negative': {'O': 0.39766081871345027, 'I-negative': 0.6023391812865497}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_transition_parameters_test(es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_emission_params(train_data,k=1):\n",
    "\n",
    "    word_sentiment_counts = defaultdict(lambda: defaultdict(int))\n",
    "    sentiment_counts =  defaultdict(int)\n",
    "    emission_params = {}\n",
    "    \n",
    "    #getting the count(y) and count(y --> x)\n",
    "    for sentence in train_data:\n",
    "        try:\n",
    "            if(sentence!=\"\"):\n",
    "                x, label = sentence.split(\" \")\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        sentiment_counts[label]+=1\n",
    "\n",
    "        word_sentiment_counts[label][x]+=1\n",
    "\n",
    "    #calculating the emission parameters\n",
    "\n",
    "    for key in word_sentiment_counts:\n",
    "        for word in word_sentiment_counts[key]:\n",
    "            emission_params[(word,key)] = word_sentiment_counts[key][word]/(sentiment_counts[key])\n",
    "    # print(emission_params)\n",
    "    return emission_params, sentiment_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import heapq\n",
    "\n",
    "def viterbi_topk(sentence, transition_params, emission_params, states, k):\n",
    "    n = len(sentence)\n",
    "    viterbi = [{} for _ in range(n)]\n",
    "    backpointers = [{} for _ in range(n)]\n",
    "\n",
    "    # Initialization at time step 0\n",
    "    for state in states:\n",
    "        emission_prob = emission_params.get((sentence[0], state), 1e-10)\n",
    "        viterbi[0][state] = math.log(transition_params['START'].get(state, 1e-10)) + math.log(emission_prob)\n",
    "        backpointers[0][state] = state\n",
    "\n",
    "    for z in range(1,n):\n",
    "        k_best = []\n",
    "        for state in states:\n",
    "            k_best_heap = []\n",
    "            for prev_seq in backpointers[z-1].keys():\n",
    "                # print(\"test\",prev_seq)\n",
    "                prev_state = backpointers[z-1][prev_seq]\n",
    "                emission_prob = emission_params.get((sentence[z], state), 1e-10)\n",
    "                transition_prob = transition_params[prev_state].get(state, 1e-10)\n",
    "                prob = viterbi[z - 1][prev_seq] + math.log(transition_prob) + math.log(emission_prob)\n",
    "                heapq.heappush(k_best_heap,(prob, prev_seq +\" \"+ state, state))\n",
    "                if len(k_best_heap) > k:\n",
    "                    heapq.heappop(k_best_heap)\n",
    "            for probability, state_list, status in k_best_heap:\n",
    "                viterbi[z][state_list] = probability\n",
    "                backpointers[z][state_list] = status\n",
    "            # print(k_best_heap)\n",
    "\n",
    "    # Termination step\n",
    "    k_best_seqs = []\n",
    "    for prev_seq in backpointers[n - 1]:\n",
    "        prev_state = backpointers[n-1][prev_seq]\n",
    "        transition_prob = transition_params[prev_state].get('STOP', 1e-10)\n",
    "        prob = viterbi[n - 1][prev_seq] + math.log(transition_prob)\n",
    "        heapq.heappush(k_best_seqs,(prob, prev_seq, state))\n",
    "        if len(k_best_seqs) > k:\n",
    "            heapq.heappop(k_best_seqs)\n",
    "    # print(k_best_seqs)\n",
    "    k_best = []\n",
    "    for probability, state_list, status in k_best_seqs:\n",
    "        k_best.append(state_list.split(\" \"))\n",
    "    \n",
    "    k_best = k_best[::-1]\n",
    "    return k_best\n",
    "\n",
    "# # # Example usage\n",
    "# transition_params = {\n",
    "#     'START': {'Noun': 0.7, 'Verb': 0.2, 'Adj': 0.1},\n",
    "#     'Noun': {'Noun': 0.4, 'Verb': 0.3, 'Adj': 0.3, 'STOP': 0.1},\n",
    "#     'Verb': {'Noun': 0.1, 'Verb': 0.5, 'Adj': 0.3, 'STOP': 0.1},\n",
    "#     'Adj': {'Noun': 0.3, 'Verb': 0.2, 'Adj': 0.5, 'STOP': 0.1},\n",
    "# }\n",
    "\n",
    "# emission_params = {\n",
    "#     ('apple', 'Noun'): 0.6,\n",
    "#     ('eats', 'Verb'): 0.8,\n",
    "#     ('red', 'Adj'): 0.7,\n",
    "#     ('apple', 'Verb'): 0.1,\n",
    "#     ('eats', 'Adj'): 0.1,\n",
    "#     ('red', 'Noun'): 0.1,\n",
    "#     ('apple', 'Adj'): 0.1,\n",
    "#     ('eats', 'Noun'): 0.1,\n",
    "#     ('red', 'Verb'): 0.1,\n",
    "# }\n",
    "\n",
    "# states = ['Noun', 'Verb', 'Adj']\n",
    "\n",
    "# sentence = ['apple', 'eats', 'red']\n",
    "# k_best_seqs = viterbi_topk(sentence, transition_params, emission_params, states, k=8)\n",
    "# print(k_best_seqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# import heapq\n",
    "\n",
    "# def viterbi_topk(sentence, transition_params, emission_params, states, k):\n",
    "#     n = len(sentence)\n",
    "#     viterbi = [{} for _ in range(n)]\n",
    "#     backpointers = [{} for _ in range(n)]\n",
    "\n",
    "#     # Initialization at time step 0\n",
    "#     for state in states:\n",
    "#         emission_prob = emission_params.get((sentence[0], state), 1e-10)\n",
    "#         viterbi[0][state] = math.log(transition_params['START'].get(state, 1e-10)) + math.log(emission_prob)\n",
    "#         backpointers[0][state] = state\n",
    "\n",
    "#     for z in range(1,n):\n",
    "#         k_best = []\n",
    "#         for state in states:\n",
    "#             k_best_heap = []\n",
    "#             for prev_seq in backpointers[z-1].keys():\n",
    "#                 # print(\"test\",prev_seq)\n",
    "#                 prev_state = backpointers[z-1][prev_seq]\n",
    "#                 emission_prob = emission_params.get((sentence[z], state), 1e-10)\n",
    "#                 transition_prob = transition_params[prev_state].get(state, 1e-10)\n",
    "#                 prob = viterbi[z - 1][prev_seq] + math.log(transition_prob) + math.log(emission_prob)\n",
    "#                 heapq.heappush(k_best_heap,(prob, prev_seq +\" \"+ state, state))\n",
    "#                 if len(k_best_heap) > 30:\n",
    "#                     heapq.heappop(k_best_heap)\n",
    "#             for probability, state_list, status in k_best_heap:\n",
    "#                 viterbi[z][state_list] = probability\n",
    "#                 backpointers[z][state_list] = status\n",
    "#             # print(k_best_heap)\n",
    "\n",
    "#     # Termination step\n",
    "#     k_best_seqs = []\n",
    "#     for prev_seq in backpointers[n - 1]:\n",
    "#         # print(\"prev1\",prev_seq,\"prev_s: \",backpointers[n-1][prev_seq])\n",
    "#         prev_state = backpointers[n-1][prev_seq]\n",
    "\n",
    "#         transition_prob = transition_params[prev_state].get('STOP', 1e-10)\n",
    "#         prob = viterbi[n - 1][prev_seq] + math.log(transition_prob)\n",
    "#         # print(prob, prev_seq, state)\n",
    "#         heapq.heappush(k_best_seqs,(prob, prev_seq, prev_state))\n",
    "#         if len(k_best_seqs) > k:\n",
    "#             heapq.heappop(k_best_seqs)\n",
    "#     # print(\"k-seq\",k_best_seqs)\n",
    "    \n",
    "#     k_best = []\n",
    "#     for probability, state_list, status in k_best_seqs:\n",
    "#         k_best.append(state_list.split(\" \"))\n",
    "    \n",
    "#     k_best = k_best[::-1]\n",
    "#     # print(k_best)\n",
    "#     return k_best\n",
    "\n",
    "# # # # Example usage\n",
    "# # transition_params = {\n",
    "# #     'START': {'Noun': 0.7, 'Verb': 0.2, 'Adj': 0.1},\n",
    "# #     'Noun': {'Noun': 0.4, 'Verb': 0.3, 'Adj': 0.3, 'STOP': 0.1},\n",
    "# #     'Verb': {'Noun': 0.1, 'Verb': 0.5, 'Adj': 0.3, 'STOP': 0.1},\n",
    "# #     'Adj': {'Noun': 0.3, 'Verb': 0.2, 'Adj': 0.5, 'STOP': 0.1},\n",
    "# # }\n",
    "\n",
    "# # emission_params = {\n",
    "# #     ('apple', 'Noun'): 0.6,\n",
    "# #     ('eats', 'Verb'): 0.8,\n",
    "# #     ('red', 'Adj'): 0.7,\n",
    "# #     ('apple', 'Verb'): 0.1,\n",
    "# #     ('eats', 'Adj'): 0.1,\n",
    "# #     ('red', 'Noun'): 0.1,\n",
    "# #     ('apple', 'Adj'): 0.1,\n",
    "# #     ('eats', 'Noun'): 0.1,\n",
    "# #     ('red', 'Verb'): 0.1,\n",
    "# # }\n",
    "\n",
    "# # states = ['Noun', 'Verb', 'Adj']\n",
    "\n",
    "# # sentence = ['apple', 'eats', 'red']\n",
    "# # k_best_seqs = viterbi_topk(sentence, transition_params, emission_params, states, k=8)\n",
    "# # print(k_best_seqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_viterbi_on_dev_set_k(dev_set, transition_params, emission_params, states, k=8):\n",
    "    output = []\n",
    "    list_of_sentences = [list(sub) for ele, sub in groupby(dev_set, key = bool) if ele]\n",
    "    for sentence in list_of_sentences:\n",
    "        best_path = viterbi_topk(sentence, transition_params, emission_params, states, k)\n",
    "        output.append(best_path)\n",
    "    # print(output)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_params_es = estimate_transition_parameters_test(es)\n",
    "emission_params_es,count = estimate_emission_params(es)\n",
    "transition_params_ru = estimate_transition_parameters_test(ru)\n",
    "emission_params_ru,count = estimate_emission_params(ru)\n",
    "# Run Viterbi algorithm on the development set\n",
    "states = []\n",
    "for i in count.keys():\n",
    "    states.append(i)\n",
    "predicted_tags_ES = run_viterbi_on_dev_set_k(dev_in_es, transition_params_es, emission_params_es, states)\n",
    "predicted_tags_RU = run_viterbi_on_dev_set_k(dev_in_ru, transition_params_ru, emission_params_ru, states)\n",
    "\n",
    "def actual_word(test_set): \n",
    "    tags =[]\n",
    "    list_of_sentences = [list(sub) for ele, sub in groupby(test_set, key = bool) if ele]\n",
    "    for sentence in list_of_sentences:\n",
    "        innerlist =[]\n",
    "        for word in sentence:\n",
    "            innerlist.append(word)\n",
    "        tags.append(innerlist)\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_words_ES = actual_word(dev_in_es)\n",
    "actual_words_RU = actual_word(dev_in_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_2_ES =[]\n",
    "sentences_8_ES = []\n",
    "sentences_2_RU =[]\n",
    "sentences_8_RU = []\n",
    "for i in predicted_tags_ES:\n",
    "    sentences_2_ES.append(i[1])\n",
    "    if len(i)>8:\n",
    "        sentences_8_ES.append(i[7])\n",
    "    else:\n",
    "        sentences_8_ES.append(i[len(i)-1])\n",
    "\n",
    "for i in predicted_tags_RU:\n",
    "    sentences_2_RU.append(i[1])\n",
    "    if len(i)>8:\n",
    "        sentences_8_RU.append(i[7])\n",
    "    else:\n",
    "        sentences_8_RU.append(i[len(i)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def compute_output(words, predicted_tags):\n",
    "    output_captured = []\n",
    "\n",
    "    for word, pred_tag in zip(words, predicted_tags):\n",
    "        for w, pred in zip(word, pred_tag):\n",
    "            output_captured.append(w + \" \" + pred)  # Append the combined word and tag\n",
    "        output_captured.append(\"\")  # Append an empty line after each sentence\n",
    "    return output_captured  # Return the captured output as a list\n",
    "\n",
    "\n",
    "# Call the compute_output function with actual_words and sentences_8\n",
    "output_captured_8_ES = compute_output(actual_words_ES, sentences_8_ES)\n",
    "output_captured_2_ES = compute_output(actual_words_ES, sentences_2_ES)\n",
    "output_captured_8_RU = compute_output(actual_words_RU, sentences_8_RU)\n",
    "output_captured_2_RU = compute_output(actual_words_RU, sentences_2_RU)\n",
    "\n",
    "# Write the captured output to a text file\n",
    "output_filename_2 = \"dev.p3.2nd.out\"  # Change this to your desired filename\n",
    "output_filename_8 = \"dev.p3.8th.out\"\n",
    "output_path_ES = \"Data/ES/\"  # Change this to your desired folder\n",
    "output_path_RU = \"Data/RU/\"\n",
    "\n",
    "with open(output_path_ES + output_filename_2, \"w\") as file:\n",
    "    for line in output_captured_2_ES:\n",
    "        file.write(line + \"\\n\")\n",
    "\n",
    "with open(output_path_ES + output_filename_8, \"w\") as file:\n",
    "    for line in output_captured_8_ES:\n",
    "        file.write(line + \"\\n\")\n",
    "\n",
    "with open(output_path_RU + output_filename_2, \"w\") as file:\n",
    "    for line in output_captured_2_RU:\n",
    "        file.write(line + \"\\n\")\n",
    "\n",
    "with open(output_path_RU + output_filename_8, \"w\") as file:\n",
    "    for line in output_captured_8_RU:\n",
    "        file.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
