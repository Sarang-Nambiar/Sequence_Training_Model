{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Data/ES/train\", 'rb') as file:\n",
    "    EStrain_content = file.read()\n",
    "\n",
    "with open(\"Data/RU/train\", 'rb') as file:\n",
    "    RUtrain_content = file.read()\n",
    "\n",
    "with open(\"Data/ES/dev.in\", 'rb') as file:\n",
    "    ESin_content = file.read()\n",
    "\n",
    "with open(\"Data/RU/dev.in\", 'rb') as file:\n",
    "    RUin_content = file.read()\n",
    "\n",
    "estrain = [line.decode('utf-8')  for line in EStrain_content.split(b'\\n')]\n",
    "rutrain = [line.decode('utf-8') for line in RUtrain_content.split(b'\\n')]\n",
    "esin = [line.decode('utf-8') for line in ESin_content.split(b'\\n')]\n",
    "ruin = [line.decode('utf-8') for line in RUin_content.split(b'\\n')]\n",
    "\n",
    "\n",
    "\n",
    "def estimate_emissions(data, k=1):\n",
    "    sentiment_count = {}\n",
    "    emission_parameters = {}\n",
    "    \n",
    "    for line in data:\n",
    "        if line == \"\" or ' ' not in line:  # Modified this condition\n",
    "            continue\n",
    "        \n",
    "        word, sentiment = line.rsplit(' ', 1)\n",
    "        if sentiment not in sentiment_count.keys():\n",
    "            sentiment_count[sentiment] = 1\n",
    "        else:\n",
    "            sentiment_count[sentiment] += 1\n",
    "            \n",
    "        if word not in emission_parameters.keys():\n",
    "            emission_parameters[word] = {sentiment:1}\n",
    "        elif word in emission_parameters.keys() and sentiment not in emission_parameters[word]:\n",
    "            emission_parameters[word][sentiment] = 1\n",
    "        else:\n",
    "            emission_parameters[word][sentiment] += 1\n",
    "            \n",
    "    emission_parameters[\"#UNK#\"] = {}\n",
    "    \n",
    "    for sentiment in sentiment_count.keys():\n",
    "        emission_parameters['#UNK#'][sentiment] = k\n",
    "        sentiment_count[sentiment] += k\n",
    "        \n",
    "    for word, sentiment in emission_parameters.items():\n",
    "        for sentiment, count in sentiment.items():\n",
    "            emission_parameters[word][sentiment] = count/sentiment_count[sentiment]\n",
    "            \n",
    "    return emission_parameters\n",
    "\n",
    "\n",
    "def sentiment_analysis(data):\n",
    "    params = estimate_emissions(data)\n",
    "    tag_dict = {}\n",
    "    for word, sentiment in params.items():\n",
    "        tag = max(sentiment, key = sentiment.get)\n",
    "        tag_dict[word] = tag\n",
    "    return tag_dict\n",
    "        \n",
    "estags = sentiment_analysis(estrain)\n",
    "rutags = sentiment_analysis(rutrain)\n",
    "\n",
    "with open(\"Data/ES/dev.p1.out\", \"w\", encoding = 'utf-8') as file:\n",
    "    for word in esin:\n",
    "        if word == \"\":\n",
    "            line = \"\"\n",
    "        elif word not in estags.keys():\n",
    "            sentiment = estags[\"#UNK#\"]\n",
    "            line = f\"{word} {sentiment}\"\n",
    "        else:\n",
    "            sentiment = estags[word]\n",
    "            line = f\"{word} {sentiment}\"\n",
    "        file.write(line + \"\\n\")\n",
    "\n",
    "with open(\"Data/RU/dev.p1.out\", \"w\", encoding = 'utf-8') as file:\n",
    "    for word in ruin:\n",
    "        if word == \"\":\n",
    "            sentiment = \"\"\n",
    "        elif word not in rutags.keys():\n",
    "            sentiment = rutags[\"#UNK#\"]\n",
    "        else:\n",
    "            sentiment = rutags[word]\n",
    "        line = f\"{word} {sentiment}\"\n",
    "        file.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('START', 'O'): 1.0, ('O', 'O'): 0.9445496814189771, ('O', 'B-positive'): 0.03984845875667298, ('B-positive', 'O'): 0.8801724137931034, ('O', 'B-negative'): 0.013122094024453246, ('B-negative', 'O'): 0.821522309711286, ('O', 'B-neutral'): 0.002445324608231445, ('B-neutral', 'I-neutral'): 0.20833333333333334, ('I-neutral', 'I-neutral'): 0.6511627906976745, ('I-neutral', 'O'): 0.3488372093023256, ('B-positive', 'I-positive'): 0.11637931034482758, ('I-positive', 'I-positive'): 0.5700636942675159, ('I-positive', 'O'): 0.4299363057324841, ('B-neutral', 'O'): 0.7916666666666666, ('B-negative', 'I-negative'): 0.1784776902887139, ('I-negative', 'O'): 0.39766081871345027, ('I-negative', 'I-negative'): 0.6023391812865497, ('B-positive', 'B-neutral'): 0.0008620689655172414, ('B-positive', 'B-positive'): 0.002586206896551724, ('O', 'STOP'): 3.4441191665231616e-05}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def estimate_transition(data):\n",
    "    count = {}\n",
    "    params = {}\n",
    "    states = []\n",
    "    sentence = []\n",
    "    for line in data:\n",
    "        if line.strip() != \"\":\n",
    "            sentence.append(line.split()[-1])\n",
    "        elif sentence != [] and line == \"\":\n",
    "            states.append(sentence)\n",
    "            sentence = []\n",
    "\n",
    "    for sentence in states:\n",
    "        if \"START\" not in count.keys():\n",
    "            count[\"START\"] = 1\n",
    "        else:\n",
    "            count[\"START\"] += 1\n",
    "    \n",
    "        if (\"START\", sentence[0]) not in params.keys():\n",
    "            params[(\"START\", sentence[0])] = 1\n",
    "        else:\n",
    "            params[(\"START\", sentence[0])] += 1\n",
    "        \n",
    "        for i in range(len(sentence)):\n",
    "            if sentence[i] not in count.keys():\n",
    "                count[sentence[i]] = 1\n",
    "            else:\n",
    "                count[sentence[i]] += 1\n",
    "            if i != 0:\n",
    "                if (sentence[i-1], sentence[i]) not in params.keys():\n",
    "                    params[(sentence[i-1], sentence[i])] = 1\n",
    "                else:\n",
    "                    params[(sentence[i-1], sentence[i])] += 1\n",
    "        if \"STOP\" not in count.keys():\n",
    "            count[\"STOP\"] = 1\n",
    "        else:\n",
    "            count[\"STOP\"] += 1\n",
    "        if (sentence[-1], \"STOP\") not in params.keys():\n",
    "            params[(sentence[-1], \"STOP\")] = 1\n",
    "        else:\n",
    "            params[(sentence[-1], \"STOP\")] += 1\n",
    "    for pair in params:\n",
    "        params[pair] = params[pair]/count[pair[0]]\n",
    "    return params\n",
    "\n",
    "es_e_params = estimate_emissions(estrain)\n",
    "es_t_params = estimate_transition(estrain)\n",
    "print(es_t_params)\n",
    "ru_e_params = estimate_emissions(rutrain)\n",
    "ru_t_params = estimate_transition(rutrain)\n",
    "\n",
    "def viterbi(e_params, t_params, sentence):\n",
    "    n = len(sentence)\n",
    "    path = []\n",
    "    states = []\n",
    "    policy = {}\n",
    "    for pair in t_params.keys():\n",
    "        states.append(pair[0])\n",
    "    states = set(states)\n",
    "    matrix = [{\"START\":0}]\n",
    "    for i in range(1, n+1):\n",
    "        policy[i] = {}\n",
    "        matrix.append({})\n",
    "        word = sentence[i-1]\n",
    "        if word not in e_params.keys():\n",
    "            word = \"#UNK#\"\n",
    "        for v in e_params[word]:\n",
    "            matrix[i][v] = -np.inf\n",
    "            for u in matrix[i-1]:\n",
    "                if (u, v) not in t_params.keys():\n",
    "                    continue\n",
    "                score = matrix[i-1][u] + np.log(e_params[word][v] * t_params[(u, v)])\n",
    "                if score > matrix[i][v]:\n",
    "                    matrix[i][v] = score\n",
    "                    policy[i][v] = u\n",
    "\n",
    "    for i in range(n):\n",
    "        if all(score == -np.inf for score in matrix[i].values()):\n",
    "            return [\"O\"]*n\n",
    "    end_state = max(matrix[n], key = lambda state: matrix[n][state])\n",
    "    prev_state = end_state\n",
    "    path.append(prev_state)\n",
    "    for i in range(n, 1, -1):\n",
    "        path.append(policy[i][prev_state])\n",
    "        prev_state = policy[i][prev_state]\n",
    "    return path[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ES/dev.p2.out\", \"w\", encoding = 'utf-8') as file:\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    for line in esin:\n",
    "        if line != \"\":\n",
    "            sentence.append(line)\n",
    "        elif line == \"\" and sentence != []:\n",
    "            sentences.append(sentence)\n",
    "            sentence = []\n",
    "    for sentence in sentences:\n",
    "        path = viterbi(es_e_params, es_t_params, sentence)\n",
    "        for word, sentiment in zip(sentence, path):\n",
    "            line = f\"{word} {sentiment}\\n\"\n",
    "            file.write(line)\n",
    "        file.write(\"\\n\")\n",
    "    \n",
    "\n",
    "with open(\"RU/dev.p2.out\", \"w\", encoding = 'utf-8') as file:\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    for line in ruin:\n",
    "        if line != \"\":\n",
    "            sentence.append(line)\n",
    "        elif line == \"\" and sentence != []:\n",
    "            sentences.append(sentence)\n",
    "            sentence = []\n",
    "    for sentence in sentences:\n",
    "        path = viterbi(ru_e_params, ru_t_params, sentence)\n",
    "        for word, sentiment in zip(sentence, path):\n",
    "            line = f\"{word} {sentiment}\\n\"\n",
    "            file.write(line)\n",
    "        file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
