{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "with open(\"Data/ES/train\") as f:\n",
    "    es = f.read().splitlines()\n",
    "\n",
    "with open(\"Data/RU/train\") as f:\n",
    "    ru = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Data/ES/dev.in\") as f:\n",
    "    dev_in_es = f.read().splitlines()\n",
    "with open(\"Data/ES/dev.out\") as f:\n",
    "    dev_out_es = f.read().splitlines()\n",
    "with open(\"Data/RU/dev.in\") as f:\n",
    "    dev_in_ru = f.read().splitlines()\n",
    "with open(\"Data/RU/dev.out\") as f:\n",
    "    test_out_ru = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_emission_params(train_data,k=1):\n",
    "\n",
    "    word_sentiment_counts = defaultdict(lambda: defaultdict(int))\n",
    "    sentiment_counts =  defaultdict(int)\n",
    "    emission_params = {}\n",
    "    \n",
    "    #getting the count(y) and count(y --> x)\n",
    "    for sentence in train_data:\n",
    "        try:\n",
    "            if(sentence!=\"\"):\n",
    "                x, label = sentence.split(\" \")\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        sentiment_counts[label]+=1\n",
    "\n",
    "        word_sentiment_counts[label][x]+=1\n",
    "\n",
    "\n",
    "\n",
    "    #calculating the emission parameters\n",
    "\n",
    "    for key in word_sentiment_counts:\n",
    "        for word in word_sentiment_counts[key]:\n",
    "            emission_params[(word,key)] = word_sentiment_counts[key][word]/(sentiment_counts[key])\n",
    "    # print(emission_params)\n",
    "    return emission_params, sentiment_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.238656605240146e-05\n",
      "count ['O', 'B-positive', 'B-negative', 'B-neutral', 'I-neutral', 'I-positive', 'I-negative']\n"
     ]
    }
   ],
   "source": [
    "es_para, count =estimate_emission_params(es)\n",
    "print(es_para[(\"palo\", \"O\")])\n",
    "states = []\n",
    "for i in count.keys():\n",
    "    states.append(i)\n",
    "print(\"count\", states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "def estimate_transition_parameters_test(sentences):\n",
    "    transition_counts = {}\n",
    "    state_counts = {}\n",
    "    list_of_sentences = [list(sub) for ele, sub in groupby(sentences, key = bool) if ele]\n",
    "    for one_sentence in list_of_sentences:\n",
    "        # print(one_sentence)\n",
    "        prev_state = 'START'\n",
    "        for one_word in one_sentence:\n",
    "            if(one_word!=\"\"):\n",
    "                #print(one_word)\n",
    "                word, state = one_word.split(\" \")\n",
    "                if state_counts.get(prev_state):\n",
    "                    state_counts[prev_state] +=1\n",
    "                else:\n",
    "                    state_counts[prev_state] = 1\n",
    "                \n",
    "\n",
    "                if prev_state not in transition_counts:\n",
    "                    transition_counts[prev_state] = {}\n",
    "                if state not in transition_counts[prev_state]:\n",
    "                    transition_counts[prev_state][state] = 1\n",
    "                else:\n",
    "                    transition_counts[prev_state][state] += 1\n",
    "                prev_state = state\n",
    "        if \"END\" not in transition_counts[prev_state]:\n",
    "            transition_counts[prev_state][\"END\"] = 1\n",
    "        else: \n",
    "            transition_counts[prev_state][\"END\"] +=1\n",
    "        # print(transition_counts)\n",
    "    for from_state, to_states in transition_counts.items():\n",
    "        # print(f\"From State: {from_state}\")\n",
    "        for to_state, count in to_states.items():\n",
    "            transition_counts[from_state][to_state] = count/state_counts[from_state]\n",
    "            # print(f\"  To State: {to_state}, Count: {count}\")\n",
    "    # print(transition_counts)    \n",
    "\n",
    "            \n",
    "\n",
    "    # print(\"transition\", transition_counts, \"state\", state_counts)       \n",
    "    return transition_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'START': {'O': 0.9289176090468497,\n",
       "  'B-positive': 0.052234787291330104,\n",
       "  'B-negative': 0.014001077005923533,\n",
       "  'B-neutral': 0.004846526655896607},\n",
       " 'O': {'O': 0.9456845511712573,\n",
       "  'B-positive': 0.038980620012503214,\n",
       "  'END': 0.06773802081418012,\n",
       "  'B-negative': 0.013054830287206266,\n",
       "  'B-neutral': 0.002279998529033207},\n",
       " 'B-positive': {'O': 0.8791304347826087,\n",
       "  'I-positive': 0.11739130434782609,\n",
       "  'END': 0.008695652173913044,\n",
       "  'B-neutral': 0.0008695652173913044,\n",
       "  'B-positive': 0.0026086956521739132},\n",
       " 'B-negative': {'O': 0.8196286472148541,\n",
       "  'I-negative': 0.18037135278514588,\n",
       "  'END': 0.010610079575596816},\n",
       " 'B-neutral': {'I-neutral': 0.20833333333333334, 'O': 0.7916666666666666},\n",
       " 'I-neutral': {'I-neutral': 0.6511627906976745, 'O': 0.3488372093023256},\n",
       " 'I-positive': {'I-positive': 0.5718849840255591,\n",
       "  'O': 0.4281150159744409,\n",
       "  'END': 0.003194888178913738},\n",
       " 'I-negative': {'O': 0.39766081871345027, 'I-negative': 0.6023391812865497}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_transition_parameters_test(es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def viterbi_algorithm_2(sentence, transition_params, emission_params, states):\n",
    "    n = len(sentence)\n",
    "    num_states = len(states)\n",
    "    viterbi = [{} for _ in range(n)]\n",
    "    backpointers = [{} for _ in range(n)]\n",
    "\n",
    "    # Initialization at time step 0\n",
    "    for state in states:\n",
    "        emission_prob = emission_params.get((sentence[0], state), 1e-10)\n",
    "        viterbi[0][state] = math.log(transition_params['START'].get(state, 1e-10)) + math.log(emission_prob)\n",
    "        backpointers[0][state] = 'START'\n",
    "\n",
    "    # Forward pass\n",
    "    for t in range(1, n):\n",
    "        for state in states:\n",
    "            max_prob = float('-inf')\n",
    "            prev_state = None\n",
    "            for prev_state in states:\n",
    "                transition_prob = transition_params[prev_state].get(state, 1e-10)\n",
    "                emission_prob = emission_params.get((sentence[t], state), 1e-10)\n",
    "                prob = viterbi[t - 1].get(prev_state,1e-10) + math.log(transition_prob) + math.log(emission_prob)\n",
    "                if prob > max_prob:\n",
    "                    max_prob = prob\n",
    "                    backpointers[t][state] = prev_state\n",
    "            viterbi[t][state] = max_prob\n",
    "\n",
    "    # Termination step\n",
    "    max_prob = float('-inf')\n",
    "    final_state = None\n",
    "    for state in states:\n",
    "        # print(viterbi[n - 1][state])\n",
    "        transition_prob = transition_params[state].get('STOP', 1e-10)\n",
    "        prob = viterbi[n - 1][state] + math.log(transition_prob)\n",
    "        if prob > max_prob:\n",
    "            max_prob = prob\n",
    "            final_state = state\n",
    "\n",
    "    # Backtracking step\n",
    "    best_path = [final_state]\n",
    "    for t in range(n - 1, 0, -1):\n",
    "        best_path.insert(0, backpointers[t][best_path[0]])\n",
    "\n",
    "    return best_path\n",
    "\n",
    "def run_viterbi_on_dev_set_2(dev_set, transition_params, emission_params, states):\n",
    "    output = []\n",
    "    list_of_sentences = [list(sub) for ele, sub in groupby(dev_set, key = bool) if ele]\n",
    "    for sentence in list_of_sentences:\n",
    "        best_path = viterbi_algorithm_2(sentence, transition_params, emission_params, states)\n",
    "        output.append(best_path)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3998 4312\n",
      "Precision: 0.9271799628942486\n",
      "4032 4312\n",
      "Precision2: 0.935064935064935\n"
     ]
    }
   ],
   "source": [
    "# Assume train_set, dev_in, and dev_out are lists of sentences and words\n",
    "# with their corresponding tags\n",
    "\n",
    "# Train the model on the training set\n",
    "transition_params = estimate_transition_parameters_test(es)\n",
    "emission_params,count = estimate_emission_params(es)\n",
    "# print(transition_params.get(\"START\",1e-10))\n",
    "states = []\n",
    "for i in count.keys():\n",
    "    states.append(i)\n",
    "# Run Viterbi algorithm on the development set\n",
    "predicted_tags = run_viterbi_on_dev_set(dev_in_es, transition_params, emission_params, states)\n",
    "\n",
    "predicted_tags_2 = run_viterbi_on_dev_set_2(dev_in_es, transition_params, emission_params, states)\n",
    "# Compute metrics\n",
    "def actual_tags(test_set):\n",
    "    tags =[]\n",
    "    list_of_sentences = [list(sub) for ele, sub in groupby(test_set, key = bool) if ele]\n",
    "    for sentence in list_of_sentences:\n",
    "        innerlist =[]\n",
    "        for word in sentence:\n",
    "            w, state = word.split()\n",
    "            innerlist.append(state)\n",
    "        tags.append(innerlist)\n",
    "    return tags\n",
    "\n",
    "# precision, recall, f_score = compute_metrics(actual_tags(dev_out_es), predicted_tags)\n",
    "precision = scores(actual_tags(dev_out_es), predicted_tags)\n",
    "print(\"Precision:\", precision)\n",
    "precision_2 = scores(actual_tags(dev_out_es), predicted_tags_2)\n",
    "print(\"Precision2:\", precision_2)\n",
    "# print(\"Recall:\", recall)\n",
    "# print(\"F-score:\", f_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3 (v3.11.3:f3909b8bc8, Apr  4 2023, 20:12:10) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
